{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#all in one"
      ],
      "metadata": {
        "id": "LG3C-Kkf19Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ws1\n",
        "#qn1\n",
        "from PIL import Image\n",
        "img=Image.open(\"/content/drive/MyDrive/images/image9.webp\")\n",
        "print(img.size)\n",
        "for i in range(0, img.size[0]-1):\n",
        "    for j in range(0, img.size[1]-1):\n",
        "        pixelColorVals = img.getpixel((i,j));\n",
        "        # Invert color\n",
        "        redPixel    = 255 - pixelColorVals[0]; # Negate red pixe\n",
        "        greenPixel  = 255 - pixelColorVals[1]; # Negate green pixel\n",
        "        bluePixel   = 255 - pixelColorVals[2]; # Negate blue pixel\n",
        "        # Modify the image with the inverted pixel values\n",
        "        img.putpixel((i,j),(redPixel, greenPixel, bluePixel));\n",
        "# Display the negative image\n",
        "img\n",
        "\n",
        "#qn2\n",
        "from PIL import Image\n",
        "img=Image.open(\"/content/drive/MyDrive/images/image1.png\")\n",
        "img=img.convert(\"L\")\n",
        "BW=img.convert('1')\n",
        "BW\n",
        "\n",
        "#qn3\n",
        "#qn3\n",
        "# Import necessary libraries\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "path = r'/content/drive/MyDrive/images/sample.mp4'\n",
        "i = 1\n",
        "video = cv2.VideoCapture(path)\n",
        "while True:\n",
        "\tret, img = video.read()\n",
        "\tcv2_imshow(img)\n",
        "\tif i>2:\n",
        "\t\tbreak\n",
        "\tfilename = 'Frames '+str(i)+'.jpg'\n",
        "\t# Save the images in given path\n",
        "\tcv2.imwrite(filename, img)\n",
        "\ti = i+1\n",
        "# close the camera\n",
        "video.release()\n",
        "# close open windows\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "#qn4\n",
        "\n",
        "img1=Image.open(\"/content/Frames 1.jpg\")\n",
        "img2=Image.open(\"/content/Frames 2.jpg\")\n",
        "from PIL import ImageChops\n",
        "img1 = img1.resize((1080,720))\n",
        "img2 = img2.resize((1080,720))\n",
        "img = ImageChops.difference(img1 , img2 )\n",
        "img\n",
        "\n",
        "\n",
        "#qn5\n",
        "img1=Image.open(\"/content/drive/MyDrive/images/image1.png\")\n",
        "img2=Image.open(\"/content/drive/MyDrive/images/image2.png\")\n",
        "img1 = img1.resize((1080,720))\n",
        "img2 = img2.resize((1080,720))\n",
        "img = Image.blend(img1 , img2 , 0.5)\n",
        "img\n",
        "\n",
        "\n",
        "#qn 6\n",
        "from PIL import ImageChops\n",
        "img1 = img1.resize((1080,720))\n",
        "img2 = img2.resize((1080,720))\n",
        "img = ImageChops.difference(img1 , img2 )\n",
        "img\n",
        "\n",
        "\n",
        "#qn 7\n",
        "\n",
        "#qn7a\n",
        "img = img2.transpose(method= Image.AFFINE )\n",
        "img\n",
        "\n",
        "#qn7a\n",
        "from PIL import Image\n",
        "#qn7a\n",
        "from PIL import Image\n",
        "a = 1\n",
        "b = 2\n",
        "c = 0 \n",
        "d = 2\n",
        "e = 1\n",
        "f = 0 \n",
        "img = img1.transform(img.size, Image.AFFINE, (a, b, c, d, e, f))\n",
        "img\n",
        "#qn 7b\n",
        "rotated_image = img1.rotate(45)\n",
        "rotated_image\n",
        "\n",
        "#qn 7c\n",
        "resized_image = img2.resize((100,100))\n",
        "resized_image\n",
        "\n",
        "#qn8\n",
        "from PIL import Image\n",
        "img = Image.open(\"/content/drive/MyDrive/images/image1.png\")\n",
        "width, height = img.size\n",
        "left = 100\n",
        "top =0.2*height\n",
        "right = 200\n",
        "bottom =width-100\n",
        "cropped_image = img.crop((left, top, right, bottom))\n",
        "cropped_image\n",
        "\n",
        "#qn9\n",
        "import numpy as np\n",
        "arr = np.array(img) \n",
        "for i in range(len(arr)) :\n",
        "  for j in range(len(arr[0])) :\n",
        "    if arr[i][j][0] >= 0 and arr[i][j][0] < 64:\n",
        "      arr[i][j][0] = arr[i][j][1] = arr[i][j][2] = 32\n",
        "    elif arr[i][j][0] >= 64 and arr[i][j][0] < 128:\n",
        "      arr[i][j][0] = arr[i][j][1] = arr[i][j][2] = 96\n",
        "    elif arr[i][j][0] >= 128 and arr[i][j][0] < 196:\n",
        "      arr[i][j][0] = arr[i][j][1] = arr[i][j][2] = 162\n",
        "    else:\n",
        "      arr[i][j][0] = arr[i][j][1] = arr[i][j][2] = 255\n",
        "img = Image.fromarray(arr)\n",
        "img\n",
        "\n",
        "#qn10\n",
        "\n",
        "#10a\n",
        "from PIL import ImageChops\n",
        "im1 = Image.open(\"/content/drive/MyDrive/images/image9.webp\") .convert(\"1\")\n",
        "im2 = Image.open(\"/content/drive/MyDrive/images/image1.png\") .convert(\"1\")\n",
        "im3 = ImageChops.logical_and(im1, im2)\n",
        "im3\n",
        "\n",
        "\n",
        "#10b\n",
        "im1 = Image.open(\"/content/drive/MyDrive/images/image9.webp\") .convert(\"1\")\n",
        "im2 = Image.open(\"/content/drive/MyDrive/images/image1.png\") .convert(\"1\")\n",
        "im3 = ImageChops.logical_or(im1, im2)\n",
        "im3\n",
        "\n",
        "#10c\n",
        "im1 = Image.open(\"/content/drive/MyDrive/images/image9.webp\") .convert(\"1\")\n",
        "im1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#ws connected component\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "imagea=np.random.randint(0,2,(8,8))\n",
        "\n",
        "plt.gray()\n",
        "plt.imshow(imagea)\n",
        "plt.show()\n",
        "\n",
        "def four_connectivity_labelling(image_array):\n",
        "  labels = np.zeros([np.size(image_array, 0), np.size(image_array, 1)], dtype = int)\n",
        "  label_count = 0\n",
        "  object_count_deduct = 0\n",
        "  equivalence_table= set()\n",
        "  for i in range(len(image_array)):\n",
        "    for j in range(len(image_array[i])):\n",
        "     if image_array[i][j]==1:\n",
        "       if i == 0 and j == 0:\n",
        "        label_count+=1\n",
        "        labels[i][j] = label_count\n",
        "       elif i > 0 and j == 0:\n",
        "        if image_array[i-1][j] == 1:\n",
        "          labels[i][j] = labels[i-1][j]\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "       elif i == 0 and j > 0:\n",
        "        if image_array[i][j-1] == 1:\n",
        "          labels[i][j] = labels[i][j-1]\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "       else:\n",
        "        if image_array[i-1][j] == 0 and image_array[i][j-1] == 1:\n",
        "          labels[i][j] = labels[i][j-1]\n",
        "        elif image_array[i-1][j] == 1 and image_array[i][j-1] == 0:\n",
        "          labels[i][j] = labels[i-1][j]\n",
        "        elif image_array[i][j-1] == 1 and image_array[i-1][j] == 1:\n",
        "          labels[i][j] = min(labels[i-1][j], labels[i][j-1])\n",
        "          if labels[i][j-1] != labels[i-1][j]:\n",
        "            equivalence_table.add(max(labels[i-1][j], labels[i][j-1]))\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "\n",
        "  print(labels)\n",
        "\n",
        "four_connectivity_labelling(imagea)\n",
        "\n",
        "#for real image \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "image_m=Image.open(\"/content/figure.png\")\n",
        "image_m\n",
        "image_m= image_m.convert('L')\n",
        "image_m\n",
        "BW= image_m.convert('1')\n",
        "BW\n",
        "img_arr = np.array(BW)\n",
        "def four_connectivity_labelling(image_array):\n",
        "  labels = np.zeros([np.size(image_array, 0), np.size(image_array, 1)], dtype = int)\n",
        "  label_count = 0\n",
        "  object_count_deduct = 0\n",
        "  equivalence_table= set()\n",
        "  for i in range(len(image_array)):\n",
        "    for j in range(len(image_array[i])):\n",
        "     if image_array[i][j]==1:\n",
        "       if i == 0 and j == 0:\n",
        "        label_count+=1\n",
        "        labels[i][j] = label_count\n",
        "       elif i > 0 and j == 0:\n",
        "        if image_array[i-1][j] == 1:\n",
        "          labels[i][j] = labels[i-1][j]\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "       elif i == 0 and j > 0:\n",
        "        if image_array[i][j-1] == 1:\n",
        "          labels[i][j] = labels[i][j-1]\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "       else:\n",
        "        if image_array[i-1][j] == 0 and image_array[i][j-1] == 1:\n",
        "          labels[i][j] = labels[i][j-1]\n",
        "        elif image_array[i-1][j] == 1 and image_array[i][j-1] == 0:\n",
        "          labels[i][j] = labels[i-1][j]\n",
        "        elif image_array[i][j-1] == 1 and image_array[i-1][j] == 1:\n",
        "          labels[i][j] = min(labels[i-1][j], labels[i][j-1])\n",
        "          if labels[i][j-1] != labels[i-1][j]:\n",
        "            equivalence_table.add(max(labels[i-1][j], labels[i][j-1]))\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "\n",
        "  print(labels)\n",
        "  # print(equivalence_table)\n",
        "  # print(\"\\nNumber of image objects are :- \", label_count - len(equivalence_table))\n",
        "\n",
        "four_connectivity_labelling(img_arr)\n",
        "\n",
        "\n",
        "#q2\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def connected_component_label(path):\n",
        "    \n",
        "    # Getting the input image\n",
        "    img = cv2.imread(path, 0)\n",
        "    # Converting those pixels with values 1-127 to 0 and others to 1\n",
        "    img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1]\n",
        "    # Applying cv2.connectedComponents() \n",
        "    num_labels, labels = cv2.connectedComponents(img)\n",
        "    \n",
        "    # Map component labels to hue val, 0-179 is the hue range in OpenCV\n",
        "    label_hue = np.uint8(179*labels/np.max(labels))\n",
        "    blank_ch = 255*np.ones_like(label_hue)\n",
        "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
        "\n",
        "    # Converting cvt to BGR\n",
        "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    # set bg label to black\n",
        "    labeled_img[label_hue==0] = 0\n",
        "    \n",
        "    \n",
        "    # Showing Original Image\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Orginal Image\")\n",
        "    plt.show()\n",
        "    \n",
        "    #Showing Image after Component Labeling\n",
        "    plt.imshow(cv2.cvtColor(labeled_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Image after Component Labeling\")\n",
        "    plt.show()\n",
        "connected_component_label('/content/images.png')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#ws noise andannotation\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def add_salt_pepper_noise(image, prob):\n",
        "    output = np.copy(image)\n",
        "    thres = 1 - prob\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            rdn = np.random.random()\n",
        "            if rdn < prob:\n",
        "                output[i][j] = 0\n",
        "            elif rdn > thres:\n",
        "                output[i][j] = 255\n",
        "    return output\n",
        "\n",
        "img = cv2.imread(\"bird.jpg\")\n",
        "print(\"\\nOriginal Image\\n\")\n",
        "cv2_imshow(img)\n",
        "noisy_img = add_salt_pepper_noise(img, 0.05)\n",
        "cv2.imwrite(\"noisy_salt_and_pepper_image.jpg\", noisy_img)\n",
        "print(\"\\nSalt and pepper Noisy image\\n\")\n",
        "cv2_imshow(noisy_img)\n",
        "\n",
        "# Use Skimage library and generate Gaussian noise, Poisson noise, Salt and Pepper noise. Add these noise images to the original image and store them in different names.\n",
        "\n",
        "import skimage\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "img = io.imread(\"dog.jpg\")\n",
        "io.imshow(img)\n",
        "\n",
        "def add_gaussian_noise(image, prob):\n",
        "    gaussian_noise = skimage.util.random_noise(image, mode='gaussian', var=prob)\n",
        "    io.imsave(\"gaussian_noise.jpg\",img_as_ubyte(img))\n",
        "    io.imshow(gaussian_noise)\n",
        "\n",
        "\n",
        "print(\"\\nGaussian Noise : \\n\")\n",
        "add_gaussian_noise(img, 0.05)\n",
        "\n",
        "def add_poisson_noise(image, prob):\n",
        "    poisson_noise = skimage.util.random_noise(image, mode='poisson')\n",
        "    io.imsave(\"poisson_noise.jpg\", img_as_ubyte(poisson_noise))\n",
        "    io.imshow(poisson_noise)\n",
        "\n",
        "print(\"\\nPoisson Noise : \\n\")\n",
        "add_poisson_noise(img, 0.05)\n",
        "\n",
        "def add_saltandpepper_noise(image, prob):\n",
        "    salt_pepper_noise = skimage.util.random_noise(image, mode='s&p', amount=0.05)\n",
        "    io.imsave(\"salt_pepper_noise.jpg\", img_as_ubyte(salt_pepper_noise))\n",
        "    io.imshow(salt_pepper_noise)\n",
        "\n",
        "print(\"\\nSalt and Pepper Noise : \\n\")\n",
        "add_saltandpepper_noise(img, 0.05)\n",
        "\n",
        "\n",
        "# For the newly generated images, apply mean filter, median filter and analyze the effectiveness.\n",
        "\n",
        "def analyze_filters(img_paths):\n",
        "    for img_path in img_paths:\n",
        "        img = cv2.imread(img_path)\n",
        "        \n",
        "        # Mean filter\n",
        "        mean_filter = cv2.blur(img,(3,3))\n",
        "        mean_psnr = cv2.PSNR(img, mean_filter)\n",
        "        print(f\"PSNR for {img_path} with mean filter: {mean_psnr}\")\n",
        "\n",
        "        # Median filter\n",
        "        median_filter = cv2.medianBlur(img,3)\n",
        "        median_psnr = cv2.PSNR(img, median_filter)\n",
        "        print(f\"PSNR for {img_path} with median filter: {median_psnr}\")\n",
        "\n",
        "# Example usage\n",
        "img_paths = [\"gaussian_noise.jpg\", \"poisson_noise.jpg\", \"salt_pepper_noise.jpg\"]\n",
        "analyze_filters(img_paths)\n",
        "\n",
        "#Text on Images\n",
        "\n",
        "img = cv2.imread(\"flower.jpg\")\n",
        "imageText = img.copy()\n",
        "text = 'This is a sample text'\n",
        "org = (30,70)\n",
        "\n",
        "# Text on the input image\n",
        "cv2.putText(imageText, text, org, fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.8, color = (0,0,0))\n",
        "\n",
        "cv2_imshow(imageText)\n",
        "\n",
        "#RECTANGLE\n",
        "\n",
        "imageRectangle = img.copy()\n",
        "\n",
        "# starting and end points of the rectangle\n",
        "start_point =(200,75)\n",
        "end_point =(475,225)\n",
        "\n",
        "cv2.rectangle(imageRectangle, start_point, end_point, (0, 0, 0), thickness= 3, lineType=cv2.LINE_8) \n",
        "\n",
        "cv2_imshow(imageRectangle)\n",
        "\n",
        "\n",
        "#circle\n",
        "imageCircle = img.copy()\n",
        "imageFilledCircle = img.copy()\n",
        "circle_center = (175,90)\n",
        "radius =80\n",
        "print(\"\\nCircle\\n\")\n",
        "cv2.circle(imageCircle, circle_center, radius, (0, 0, 0), thickness=3, lineType=cv2.LINE_AA) \n",
        "cv2_imshow(imageCircle)\n",
        "print(\"\\nFilled circle\\n\")\n",
        "cv2.circle(imageFilledCircle, circle_center, radius, (0, 0, 0), thickness=-1, lineType=cv2.LINE_AA)\n",
        "cv2_imshow(imageFilledCircle)\n",
        "\n",
        "\n",
        "#line\n",
        "imageLine = img.copy()\n",
        "pointA = (5,220)\n",
        "pointB = (250,220)\n",
        "cv2.line(imageLine, pointA, pointB, (0, 0, 0), thickness=3)\n",
        "cv2_imshow(imageLine)\n",
        "\n",
        "\n",
        "#ellipse\n",
        "imageEllipse = img.copy()\n",
        "ellipse_center = (415,190)\n",
        "axis1 = (75,40)\n",
        "axis2 = (100,40)\n",
        "cv2.ellipse(imageEllipse, ellipse_center, axis1, 0, 0, 360, (170, 51, 106), thickness=3)\n",
        "cv2.ellipse(imageEllipse, ellipse_center, axis2, 90, 0, 360, (144, 238, 144), thickness=3)\n",
        "cv2_imshow(imageEllipse)\n",
        "\n",
        "\n",
        "#halfellipse\n",
        "halfEllipse = img.copy()\n",
        "ellipse_center = (315,190)\n",
        "\n",
        "axis1 = (100,50)\n",
        "\n",
        "cv2.ellipse(halfEllipse, ellipse_center, axis1, 0, 180, 360, (170, 51, 106), thickness=3)\n",
        "cv2.ellipse(halfEllipse, ellipse_center, axis1, 0, 0, 180, (144, 238, 144), thickness=-2)\n",
        "cv2_imshow(halfEllipse)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#ws color spacetransform and convolution\n",
        "\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "bright = cv2.imread('/content/drive/MyDrive/cube.png')\n",
        "dark = cv2.imread('/content/drive/MyDrive/dark_cube.png')\n",
        "cv2_imshow(bright)\n",
        "print(\"\\n\")\n",
        "cv2_imshow(dark)\n",
        "#rgb to lab\n",
        "brightLAB = cv2.cvtColor(bright, cv2.COLOR_BGR2LAB)\n",
        "darkLAB = cv2.cvtColor(dark, cv2.COLOR_BGR2LAB)\n",
        "cv2_imshow(brightLAB)\n",
        "print(\"\\n\")\n",
        "cv2_imshow(darkLAB)\n",
        "\n",
        "#RGB To YCrCb\n",
        "brightYCB = cv2.cvtColor(bright, cv2.COLOR_BGR2YCrCb)\n",
        "darkYCB = cv2.cvtColor(dark, cv2.COLOR_BGR2YCrCb)\n",
        "cv2_imshow(brightLAB)\n",
        "print(\"\\n\")\n",
        "cv2_imshow(darkLAB)\n",
        "\n",
        "\n",
        "#RGB To HSV\n",
        "\n",
        "brightHSV = cv2.cvtColor(bright, cv2.COLOR_BGR2HSV)\n",
        "darkHSV = cv2.cvtColor(dark, cv2.COLOR_BGR2HSV)\n",
        "cv2_imshow(brightLAB)\n",
        "print(\"\\n\")\n",
        "cv2_imshow(darkLAB)\n",
        "\n",
        "\n",
        "#Create an array of size 15 x 15 containing gray intensity values. Consider another array of size 3 x 3 consisting of all 1's. Write a program to apply convolution.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_array = np.random.randint(0, 255, (15,15))\n",
        "filter_array = np.ones([3, 3], dtype = int)\n",
        "\n",
        "plt.imshow(image_array)\n",
        "plt.show()\n",
        "\n",
        "convoluted_array = np.zeros([13, 13], dtype = int)\n",
        "\n",
        "#mean filter\n",
        "def convolute_image(image_array, i,j):\n",
        "  sum=0\n",
        "  for x in range(i- int(filter_array.shape[0]/2),i+ int(filter_array.shape[0]/2)):\n",
        "    for y in range(j- int(filter_array.shape[1]/2),j+ int(filter_array.shape[1]/2)):\n",
        "      sum+=image_array[x][y]\n",
        "  return sum\n",
        "\n",
        "for i in range(1, image_array.shape[0]-filter_array.shape[0]+2):\n",
        "  for j in range(1, image_array.shape[1]-filter_array.shape[1]+2):\n",
        "    convoluted_array[i-1][j-1] = convolute_image(image_array, i ,j)\n",
        "plt.imshow(convoluted_array)\n",
        "plt.show()\n",
        "\n",
        "#edge detection\n",
        "\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/dog.jpg') \n",
        "cv2_imshow(img)\n",
        "cv2.waitKey(0)\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "img_blur = cv2.GaussianBlur(img_gray, (3,3), 0) \n",
        "sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) \n",
        "sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5)\n",
        "sobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) \n",
        "\n",
        "cv2_imshow(sobelx)\n",
        "cv2.waitKey(0)\n",
        "cv2_imshow(sobely)\n",
        "cv2.waitKey(0)\n",
        "cv2_imshow(sobelxy)\n",
        "cv2.waitKey(0)\n",
        "edges = cv2.Canny(image=img_blur, threshold1=100, threshold2=200) \n",
        "\n",
        "cv2_imshow(edges)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Canny edge detection\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image = cv2.imread(\"/content/drive/MyDrive/data/dog.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\"\"\"# Gaussian Blurring\"\"\"\n",
        "\n",
        "def gaussian(x, y, sigma):\n",
        "  return (1 / (2 * np.pi * sigma ** 2)) * np.exp(-((x**2 + y**2) / (2 * sigma ** 2)))\n",
        "\n",
        "def gaussian_kernel(size, sigma):\n",
        "  k = size // 2\n",
        "  kernel = np.zeros((size, size))\n",
        "  for i in range(2 * k + 1):\n",
        "    for j in range(2 * k + 1):\n",
        "      kernel[i][j] = gaussian(i - k, j - k, sigma)\n",
        "  \n",
        "  return kernel\n",
        "\n",
        "kernel = gaussian_kernel(5, 1)\n",
        "image_gaussian = cv2.filter2D(src=image, ddepth=-1, kernel=kernel)\n",
        "\n",
        "\"\"\"# Applying filter\"\"\"\n",
        "\n",
        "image_sobel_x = cv2.filter2D(image_gaussian, ddepth=-1, kernel=np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]))\n",
        "image_sobel_y = cv2.filter2D(image_gaussian, ddepth=-1, kernel=np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]))\n",
        "\n",
        "\"\"\"# Non max suppression\"\"\"\n",
        "\n",
        "magnitude = np.hypot(image_sobel_x, image_sobel_y)\n",
        "magnitude = (magnitude / magnitude.max()) * 255\n",
        "direction = np.arctan2(image_sobel_y, image_sobel_x)\n",
        "direction = direction * 180 / np.pi\n",
        "direction[direction < 0] += 180\n",
        "\n",
        "cv2_imshow(magnitude)\n",
        "\n",
        "image_suppressed = np.zeros((image.shape[0], image.shape[1]))\n",
        "angle_direction_mapping = {\n",
        "    (0, 22.5): (0, 1),\n",
        "    (22.5, 67.5): (-1, -1),\n",
        "    (67.5, 112.5): (1, 0),\n",
        "    (112.5, 157.5): (1, -1),\n",
        "    (157.5, 180): (0, 1)\n",
        "}\n",
        "\n",
        "for i in range(1, image.shape[0] - 1):\n",
        "  for j in range(1, image.shape[1] - 1):\n",
        "    current_pixel_value = magnitude[i][j]\n",
        "    for angle, neighbour_direction in angle_direction_mapping.items():\n",
        "      if angle[0] <= direction[i][j] < angle[1]:\n",
        "        break\n",
        "    neighbour1 = magnitude[i + neighbour_direction[0]][j + neighbour_direction[1]]\n",
        "    neighbour2 = magnitude[i - neighbour_direction[0]][j - neighbour_direction[1]]\n",
        "    if current_pixel_value >= neighbour1 and current_pixel_value >= neighbour2:\n",
        "      image_suppressed[i][j] = current_pixel_value\n",
        "    else:\n",
        "      image_suppressed[i][j] = 0\n",
        "\n",
        "# cv2_imshow((image_suppressed / image_suppressed.max()) * 255)\n",
        "cv2_imshow(image_suppressed)\n",
        "\n",
        "\"\"\"# Double Thresolding\"\"\"\n",
        "\n",
        "low_thresh_ratio = 0.05\n",
        "high_thresh_ratio = 0.09\n",
        "\n",
        "STRONG = 255\n",
        "WEAK = 25\n",
        "\n",
        "high_thresh = image_suppressed.max() * high_thresh_ratio\n",
        "low_thresh = high_thresh * low_thresh_ratio\n",
        "\n",
        "thresholded_result = np.zeros(image.shape)\n",
        "thresholded_result[image_suppressed > high_thresh] = STRONG\n",
        "thresholded_result[(image_suppressed <= high_thresh) & (image_suppressed >= low_thresh)] = WEAK\n",
        "\n",
        "cv2_imshow(thresholded_result)\n",
        "\n",
        "\"\"\"# Edge tracking by Hysterisis\"\"\"\n",
        "\n",
        "for i in range(1, image.shape[0]):\n",
        "  for j in range(1, image.shape[1]):\n",
        "    if thresholded_result[i][j] == WEAK:\n",
        "      if (thresholded_result[i - 1:i + 2, j - 1 : j + 2] == STRONG).any():\n",
        "        thresholded_result[i][j] = STRONG\n",
        "\n",
        "cv2_imshow(thresholded_result)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#PCA\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import cv2\n",
        "from scipy.stats import stats\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "img = cv2.cvtColor(cv2.imread('rose.jpg'), cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "#Splitting into channels\n",
        "blue,green,red = cv2.split(img)\n",
        "# Plotting the images\n",
        "fig = plt.figure(figsize = (15, 7.2)) \n",
        "fig.add_subplot(131)\n",
        "plt.title(\"Blue Channel\")\n",
        "plt.imshow(blue)\n",
        "fig.add_subplot(132)\n",
        "plt.title(\"Green Channel\")\n",
        "plt.imshow(green)\n",
        "fig.add_subplot(133)\n",
        "plt.title(\"Red Channel\")\n",
        "plt.imshow(red)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "blue_temp_df = pd.DataFrame(data = blue)\n",
        "blue_temp_df\n",
        "\n",
        "df_blue = blue/255\n",
        "df_green = green/255\n",
        "df_red = red/255\n",
        "\n",
        "\n",
        "pca_b = PCA(n_components=50)\n",
        "pca_b.fit(df_blue)\n",
        "trans_pca_b = pca_b.transform(df_blue)\n",
        "pca_g = PCA(n_components=50)\n",
        "pca_g.fit(df_green)\n",
        "trans_pca_g = pca_g.transform(df_green)\n",
        "pca_r = PCA(n_components=50)\n",
        "pca_r.fit(df_red)\n",
        "trans_pca_r = pca_r.transform(df_red)\n",
        "\n",
        "\n",
        "print(trans_pca_b.shape)\n",
        "print(trans_pca_r.shape)\n",
        "print(trans_pca_g.shape)\n",
        "\n",
        "\n",
        "print(f\"Blue Channel : {sum(pca_b.explained_variance_ratio_)}\")\n",
        "print(f\"Green Channel: {sum(pca_g.explained_variance_ratio_)}\")\n",
        "print(f\"Red Channel  : {sum(pca_r.explained_variance_ratio_)}\")\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (15, 7.2)) \n",
        "fig.add_subplot(131)\n",
        "plt.title(\"Blue Channel\")\n",
        "plt.ylabel('Variation explained')\n",
        "plt.xlabel('Eigen Value')\n",
        "plt.bar(list(range(1,51)),pca_b.explained_variance_ratio_)\n",
        "fig.add_subplot(132)\n",
        "plt.title(\"Green Channel\")\n",
        "plt.ylabel('Variation explained')\n",
        "plt.xlabel('Eigen Value')\n",
        "plt.bar(list(range(1,51)),pca_g.explained_variance_ratio_)\n",
        "fig.add_subplot(133)\n",
        "plt.title(\"Red Channel\")\n",
        "plt.ylabel('Variation explained')\n",
        "plt.xlabel('Eigen Value')\n",
        "plt.bar(list(range(1,51)),pca_r.explained_variance_ratio_)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#reconstruct\n",
        "b_arr = pca_b.inverse_transform(trans_pca_b)\n",
        "g_arr = pca_g.inverse_transform(trans_pca_g)\n",
        "r_arr = pca_r.inverse_transform(trans_pca_r)\n",
        "print(b_arr.shape, g_arr.shape, r_arr.shape)\n",
        "\n",
        "\n",
        "img_reduced= (cv2.merge((b_arr, g_arr, r_arr)))\n",
        "print(img_reduced.shape)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (10, 7.2)) \n",
        "fig.add_subplot(121)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(img)\n",
        "fig.add_subplot(122)\n",
        "plt.title(\"Reduced Image\")\n",
        "plt.imshow(img_reduced)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tF9UUMXM19HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO6VPfzSrAF_"
      },
      "outputs": [],
      "source": [
        "#ws1\n",
        "#qn1\n",
        "from PIL import Image\n",
        "img=Image.open(\"/content/drive/MyDrive/images/image9.webp\")\n",
        "print(img.size)\n",
        "for i in range(0, img.size[0]-1):\n",
        "    for j in range(0, img.size[1]-1):\n",
        "        pixelColorVals = img.getpixel((i,j));\n",
        "        # Invert color\n",
        "        redPixel    = 255 - pixelColorVals[0]; # Negate red pixe\n",
        "        greenPixel  = 255 - pixelColorVals[1]; # Negate green pixel\n",
        "        bluePixel   = 255 - pixelColorVals[2]; # Negate blue pixel\n",
        "        # Modify the image with the inverted pixel values\n",
        "        img.putpixel((i,j),(redPixel, greenPixel, bluePixel));\n",
        "# Display the negative image\n",
        "img\n",
        "\n",
        "#qn2\n",
        "from PIL import Image\n",
        "img=Image.open(\"/content/drive/MyDrive/images/image1.png\")\n",
        "img=img.convert(\"L\")\n",
        "BW=img.convert('1')\n",
        "BW\n",
        "\n",
        "#qn3\n",
        "#qn3\n",
        "# Import necessary libraries\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "path = r'/content/drive/MyDrive/images/sample.mp4'\n",
        "i = 1\n",
        "video = cv2.VideoCapture(path)\n",
        "while True:\n",
        "\tret, img = video.read()\n",
        "\tcv2_imshow(img)\n",
        "\tif i>2:\n",
        "\t\tbreak\n",
        "\tfilename = 'Frames '+str(i)+'.jpg'\n",
        "\t# Save the images in given path\n",
        "\tcv2.imwrite(filename, img)\n",
        "\ti = i+1\n",
        "# close the camera\n",
        "video.release()\n",
        "# close open windows\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "#qn4\n",
        "\n",
        "img1=Image.open(\"/content/Frames 1.jpg\")\n",
        "img2=Image.open(\"/content/Frames 2.jpg\")\n",
        "from PIL import ImageChops\n",
        "img1 = img1.resize((1080,720))\n",
        "img2 = img2.resize((1080,720))\n",
        "img = ImageChops.difference(img1 , img2 )\n",
        "img\n",
        "\n",
        "\n",
        "#qn5\n",
        "img1=Image.open(\"/content/drive/MyDrive/images/image1.png\")\n",
        "img2=Image.open(\"/content/drive/MyDrive/images/image2.png\")\n",
        "img1 = img1.resize((1080,720))\n",
        "img2 = img2.resize((1080,720))\n",
        "img = Image.blend(img1 , img2 , 0.5)\n",
        "img\n",
        "\n",
        "\n",
        "#qn 6\n",
        "from PIL import ImageChops\n",
        "img1 = img1.resize((1080,720))\n",
        "img2 = img2.resize((1080,720))\n",
        "img = ImageChops.difference(img1 , img2 )\n",
        "img\n",
        "\n",
        "\n",
        "#qn 7\n",
        "\n",
        "#qn7a\n",
        "img = img2.transpose(method= Image.AFFINE )\n",
        "img\n",
        "\n",
        "#qn7a\n",
        "from PIL import Image\n",
        "#qn7a\n",
        "from PIL import Image\n",
        "a = 1\n",
        "b = 2\n",
        "c = 0 \n",
        "d = 2\n",
        "e = 1\n",
        "f = 0 \n",
        "img = img1.transform(img.size, Image.AFFINE, (a, b, c, d, e, f))\n",
        "img\n",
        "#qn 7b\n",
        "rotated_image = img1.rotate(45)\n",
        "rotated_image\n",
        "\n",
        "#qn 7c\n",
        "resized_image = img2.resize((100,100))\n",
        "resized_image\n",
        "\n",
        "#qn8\n",
        "from PIL import Image\n",
        "img = Image.open(\"/content/drive/MyDrive/images/image1.png\")\n",
        "width, height = img.size\n",
        "left = 100\n",
        "top =0.2*height\n",
        "right = 200\n",
        "bottom =width-100\n",
        "cropped_image = img.crop((left, top, right, bottom))\n",
        "cropped_image\n",
        "\n",
        "#qn9\n",
        "import numpy as np\n",
        "arr = np.array(img) \n",
        "for i in range(len(arr)) :\n",
        "  for j in range(len(arr[0])) :\n",
        "    if arr[i][j][0] >= 0 and arr[i][j][0] < 64:\n",
        "      arr[i][j][0] = arr[i][j][1] = arr[i][j][2] = 32\n",
        "    elif arr[i][j][0] >= 64 and arr[i][j][0] < 128:\n",
        "      arr[i][j][0] = arr[i][j][1] = arr[i][j][2] = 96\n",
        "    elif arr[i][j][0] >= 128 and arr[i][j][0] < 196:\n",
        "      arr[i][j][0] = arr[i][j][1] = arr[i][j][2] = 162\n",
        "    else:\n",
        "      arr[i][j][0] = arr[i][j][1] = arr[i][j][2] = 255\n",
        "img = Image.fromarray(arr)\n",
        "img\n",
        "\n",
        "#qn10\n",
        "\n",
        "#10a\n",
        "from PIL import ImageChops\n",
        "im1 = Image.open(\"/content/drive/MyDrive/images/image9.webp\") .convert(\"1\")\n",
        "im2 = Image.open(\"/content/drive/MyDrive/images/image1.png\") .convert(\"1\")\n",
        "im3 = ImageChops.logical_and(im1, im2)\n",
        "im3\n",
        "\n",
        "\n",
        "#10b\n",
        "im1 = Image.open(\"/content/drive/MyDrive/images/image9.webp\") .convert(\"1\")\n",
        "im2 = Image.open(\"/content/drive/MyDrive/images/image1.png\") .convert(\"1\")\n",
        "im3 = ImageChops.logical_or(im1, im2)\n",
        "im3\n",
        "\n",
        "#10c\n",
        "im1 = Image.open(\"/content/drive/MyDrive/images/image9.webp\") .convert(\"1\")\n",
        "im1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ws connected component\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "imagea=np.random.randint(0,2,(8,8))\n",
        "\n",
        "plt.gray()\n",
        "plt.imshow(imagea)\n",
        "plt.show()\n",
        "\n",
        "def four_connectivity_labelling(image_array):\n",
        "  labels = np.zeros([np.size(image_array, 0), np.size(image_array, 1)], dtype = int)\n",
        "  label_count = 0\n",
        "  object_count_deduct = 0\n",
        "  equivalence_table= set()\n",
        "  for i in range(len(image_array)):\n",
        "    for j in range(len(image_array[i])):\n",
        "     if image_array[i][j]==1:\n",
        "       if i == 0 and j == 0:\n",
        "        label_count+=1\n",
        "        labels[i][j] = label_count\n",
        "       elif i > 0 and j == 0:\n",
        "        if image_array[i-1][j] == 1:\n",
        "          labels[i][j] = labels[i-1][j]\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "       elif i == 0 and j > 0:\n",
        "        if image_array[i][j-1] == 1:\n",
        "          labels[i][j] = labels[i][j-1]\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "       else:\n",
        "        if image_array[i-1][j] == 0 and image_array[i][j-1] == 1:\n",
        "          labels[i][j] = labels[i][j-1]\n",
        "        elif image_array[i-1][j] == 1 and image_array[i][j-1] == 0:\n",
        "          labels[i][j] = labels[i-1][j]\n",
        "        elif image_array[i][j-1] == 1 and image_array[i-1][j] == 1:\n",
        "          labels[i][j] = min(labels[i-1][j], labels[i][j-1])\n",
        "          if labels[i][j-1] != labels[i-1][j]:\n",
        "            equivalence_table.add(max(labels[i-1][j], labels[i][j-1]))\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "\n",
        "  print(labels)\n",
        "\n",
        "four_connectivity_labelling(imagea)\n",
        "\n",
        "#for real image \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "image_m=Image.open(\"/content/figure.png\")\n",
        "image_m\n",
        "image_m= image_m.convert('L')\n",
        "image_m\n",
        "BW= image_m.convert('1')\n",
        "BW\n",
        "img_arr = np.array(BW)\n",
        "def four_connectivity_labelling(image_array):\n",
        "  labels = np.zeros([np.size(image_array, 0), np.size(image_array, 1)], dtype = int)\n",
        "  label_count = 0\n",
        "  object_count_deduct = 0\n",
        "  equivalence_table= set()\n",
        "  for i in range(len(image_array)):\n",
        "    for j in range(len(image_array[i])):\n",
        "     if image_array[i][j]==1:\n",
        "       if i == 0 and j == 0:\n",
        "        label_count+=1\n",
        "        labels[i][j] = label_count\n",
        "       elif i > 0 and j == 0:\n",
        "        if image_array[i-1][j] == 1:\n",
        "          labels[i][j] = labels[i-1][j]\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "       elif i == 0 and j > 0:\n",
        "        if image_array[i][j-1] == 1:\n",
        "          labels[i][j] = labels[i][j-1]\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "       else:\n",
        "        if image_array[i-1][j] == 0 and image_array[i][j-1] == 1:\n",
        "          labels[i][j] = labels[i][j-1]\n",
        "        elif image_array[i-1][j] == 1 and image_array[i][j-1] == 0:\n",
        "          labels[i][j] = labels[i-1][j]\n",
        "        elif image_array[i][j-1] == 1 and image_array[i-1][j] == 1:\n",
        "          labels[i][j] = min(labels[i-1][j], labels[i][j-1])\n",
        "          if labels[i][j-1] != labels[i-1][j]:\n",
        "            equivalence_table.add(max(labels[i-1][j], labels[i][j-1]))\n",
        "        else:\n",
        "          label_count+=1\n",
        "          labels[i][j] = label_count\n",
        "\n",
        "  print(labels)\n",
        "  # print(equivalence_table)\n",
        "  # print(\"\\nNumber of image objects are :- \", label_count - len(equivalence_table))\n",
        "\n",
        "four_connectivity_labelling(img_arr)\n",
        "\n",
        "\n",
        "#q2\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def connected_component_label(path):\n",
        "    \n",
        "    # Getting the input image\n",
        "    img = cv2.imread(path, 0)\n",
        "    # Converting those pixels with values 1-127 to 0 and others to 1\n",
        "    img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1]\n",
        "    # Applying cv2.connectedComponents() \n",
        "    num_labels, labels = cv2.connectedComponents(img)\n",
        "    \n",
        "    # Map component labels to hue val, 0-179 is the hue range in OpenCV\n",
        "    label_hue = np.uint8(179*labels/np.max(labels))\n",
        "    blank_ch = 255*np.ones_like(label_hue)\n",
        "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
        "\n",
        "    # Converting cvt to BGR\n",
        "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    # set bg label to black\n",
        "    labeled_img[label_hue==0] = 0\n",
        "    \n",
        "    \n",
        "    # Showing Original Image\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Orginal Image\")\n",
        "    plt.show()\n",
        "    \n",
        "    #Showing Image after Component Labeling\n",
        "    plt.imshow(cv2.cvtColor(labeled_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Image after Component Labeling\")\n",
        "    plt.show()\n",
        "connected_component_label('/content/images.png')"
      ],
      "metadata": {
        "id": "Qu8zms1HrCbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ws noise andannotation\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def add_salt_pepper_noise(image, prob):\n",
        "    output = np.copy(image)\n",
        "    thres = 1 - prob\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            rdn = np.random.random()\n",
        "            if rdn < prob:\n",
        "                output[i][j] = 0\n",
        "            elif rdn > thres:\n",
        "                output[i][j] = 255\n",
        "    return output\n",
        "\n",
        "img = cv2.imread(\"bird.jpg\")\n",
        "print(\"\\nOriginal Image\\n\")\n",
        "cv2_imshow(img)\n",
        "noisy_img = add_salt_pepper_noise(img, 0.05)\n",
        "cv2.imwrite(\"noisy_salt_and_pepper_image.jpg\", noisy_img)\n",
        "print(\"\\nSalt and pepper Noisy image\\n\")\n",
        "cv2_imshow(noisy_img)\n",
        "\n",
        "# Use Skimage library and generate Gaussian noise, Poisson noise, Salt and Pepper noise. Add these noise images to the original image and store them in different names.\n",
        "\n",
        "import skimage\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "img = io.imread(\"dog.jpg\")\n",
        "io.imshow(img)\n",
        "\n",
        "def add_gaussian_noise(image, prob):\n",
        "    gaussian_noise = skimage.util.random_noise(image, mode='gaussian', var=prob)\n",
        "    io.imsave(\"gaussian_noise.jpg\",img_as_ubyte(img))\n",
        "    io.imshow(gaussian_noise)\n",
        "\n",
        "\n",
        "print(\"\\nGaussian Noise : \\n\")\n",
        "add_gaussian_noise(img, 0.05)\n",
        "\n",
        "def add_poisson_noise(image, prob):\n",
        "    poisson_noise = skimage.util.random_noise(image, mode='poisson')\n",
        "    io.imsave(\"poisson_noise.jpg\", img_as_ubyte(poisson_noise))\n",
        "    io.imshow(poisson_noise)\n",
        "\n",
        "print(\"\\nPoisson Noise : \\n\")\n",
        "add_poisson_noise(img, 0.05)\n",
        "\n",
        "def add_saltandpepper_noise(image, prob):\n",
        "    salt_pepper_noise = skimage.util.random_noise(image, mode='s&p', amount=0.05)\n",
        "    io.imsave(\"salt_pepper_noise.jpg\", img_as_ubyte(salt_pepper_noise))\n",
        "    io.imshow(salt_pepper_noise)\n",
        "\n",
        "print(\"\\nSalt and Pepper Noise : \\n\")\n",
        "add_saltandpepper_noise(img, 0.05)\n",
        "\n",
        "\n",
        "# For the newly generated images, apply mean filter, median filter and analyze the effectiveness.\n",
        "\n",
        "def analyze_filters(img_paths):\n",
        "    for img_path in img_paths:\n",
        "        img = cv2.imread(img_path)\n",
        "        \n",
        "        # Mean filter\n",
        "        mean_filter = cv2.blur(img,(3,3))\n",
        "        mean_psnr = cv2.PSNR(img, mean_filter)\n",
        "        print(f\"PSNR for {img_path} with mean filter: {mean_psnr}\")\n",
        "\n",
        "        # Median filter\n",
        "        median_filter = cv2.medianBlur(img,3)\n",
        "        median_psnr = cv2.PSNR(img, median_filter)\n",
        "        print(f\"PSNR for {img_path} with median filter: {median_psnr}\")\n",
        "\n",
        "# Example usage\n",
        "img_paths = [\"gaussian_noise.jpg\", \"poisson_noise.jpg\", \"salt_pepper_noise.jpg\"]\n",
        "analyze_filters(img_paths)\n",
        "\n",
        "#Text on Images\n",
        "\n",
        "img = cv2.imread(\"flower.jpg\")\n",
        "imageText = img.copy()\n",
        "text = 'This is a sample text'\n",
        "org = (30,70)\n",
        "\n",
        "# Text on the input image\n",
        "cv2.putText(imageText, text, org, fontFace = cv2.FONT_HERSHEY_COMPLEX, fontScale = 0.8, color = (0,0,0))\n",
        "\n",
        "cv2_imshow(imageText)\n",
        "\n",
        "#RECTANGLE\n",
        "\n",
        "imageRectangle = img.copy()\n",
        "\n",
        "# starting and end points of the rectangle\n",
        "start_point =(200,75)\n",
        "end_point =(475,225)\n",
        "\n",
        "cv2.rectangle(imageRectangle, start_point, end_point, (0, 0, 0), thickness= 3, lineType=cv2.LINE_8) \n",
        "\n",
        "cv2_imshow(imageRectangle)\n",
        "\n",
        "\n",
        "#circle\n",
        "imageCircle = img.copy()\n",
        "imageFilledCircle = img.copy()\n",
        "circle_center = (175,90)\n",
        "radius =80\n",
        "print(\"\\nCircle\\n\")\n",
        "cv2.circle(imageCircle, circle_center, radius, (0, 0, 0), thickness=3, lineType=cv2.LINE_AA) \n",
        "cv2_imshow(imageCircle)\n",
        "print(\"\\nFilled circle\\n\")\n",
        "cv2.circle(imageFilledCircle, circle_center, radius, (0, 0, 0), thickness=-1, lineType=cv2.LINE_AA)\n",
        "cv2_imshow(imageFilledCircle)\n",
        "\n",
        "\n",
        "#line\n",
        "imageLine = img.copy()\n",
        "pointA = (5,220)\n",
        "pointB = (250,220)\n",
        "cv2.line(imageLine, pointA, pointB, (0, 0, 0), thickness=3)\n",
        "cv2_imshow(imageLine)\n",
        "\n",
        "\n",
        "#ellipse\n",
        "imageEllipse = img.copy()\n",
        "ellipse_center = (415,190)\n",
        "axis1 = (75,40)\n",
        "axis2 = (100,40)\n",
        "cv2.ellipse(imageEllipse, ellipse_center, axis1, 0, 0, 360, (170, 51, 106), thickness=3)\n",
        "cv2.ellipse(imageEllipse, ellipse_center, axis2, 90, 0, 360, (144, 238, 144), thickness=3)\n",
        "cv2_imshow(imageEllipse)\n",
        "\n",
        "\n",
        "#halfellipse\n",
        "halfEllipse = img.copy()\n",
        "ellipse_center = (315,190)\n",
        "\n",
        "axis1 = (100,50)\n",
        "\n",
        "cv2.ellipse(halfEllipse, ellipse_center, axis1, 0, 180, 360, (170, 51, 106), thickness=3)\n",
        "cv2.ellipse(halfEllipse, ellipse_center, axis1, 0, 0, 180, (144, 238, 144), thickness=-2)\n",
        "cv2_imshow(halfEllipse)"
      ],
      "metadata": {
        "id": "LGLP7z68v_8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ws color spacetransform and convolution\n",
        "\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "bright = cv2.imread('/content/drive/MyDrive/cube.png')\n",
        "dark = cv2.imread('/content/drive/MyDrive/dark_cube.png')\n",
        "cv2_imshow(bright)\n",
        "print(\"\\n\")\n",
        "cv2_imshow(dark)\n",
        "#rgb to lab\n",
        "brightLAB = cv2.cvtColor(bright, cv2.COLOR_BGR2LAB)\n",
        "darkLAB = cv2.cvtColor(dark, cv2.COLOR_BGR2LAB)\n",
        "cv2_imshow(brightLAB)\n",
        "print(\"\\n\")\n",
        "cv2_imshow(darkLAB)\n",
        "\n",
        "#RGB To YCrCb\n",
        "brightYCB = cv2.cvtColor(bright, cv2.COLOR_BGR2YCrCb)\n",
        "darkYCB = cv2.cvtColor(dark, cv2.COLOR_BGR2YCrCb)\n",
        "cv2_imshow(brightLAB)\n",
        "print(\"\\n\")\n",
        "cv2_imshow(darkLAB)\n",
        "\n",
        "\n",
        "#RGB To HSV\n",
        "\n",
        "brightHSV = cv2.cvtColor(bright, cv2.COLOR_BGR2HSV)\n",
        "darkHSV = cv2.cvtColor(dark, cv2.COLOR_BGR2HSV)\n",
        "cv2_imshow(brightLAB)\n",
        "print(\"\\n\")\n",
        "cv2_imshow(darkLAB)\n",
        "\n",
        "\n",
        "#Create an array of size 15 x 15 containing gray intensity values. Consider another array of size 3 x 3 consisting of all 1's. Write a program to apply convolution.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_array = np.random.randint(0, 255, (15,15))\n",
        "filter_array = np.ones([3, 3], dtype = int)\n",
        "\n",
        "plt.imshow(image_array)\n",
        "plt.show()\n",
        "\n",
        "convoluted_array = np.zeros([13, 13], dtype = int)\n",
        "\n",
        "#mean filter\n",
        "def convolute_image(image_array, i,j):\n",
        "  sum=0\n",
        "  for x in range(i- int(filter_array.shape[0]/2),i+ int(filter_array.shape[0]/2)):\n",
        "    for y in range(j- int(filter_array.shape[1]/2),j+ int(filter_array.shape[1]/2)):\n",
        "      sum+=image_array[x][y]\n",
        "  return sum\n",
        "\n",
        "for i in range(1, image_array.shape[0]-filter_array.shape[0]+2):\n",
        "  for j in range(1, image_array.shape[1]-filter_array.shape[1]+2):\n",
        "    convoluted_array[i-1][j-1] = convolute_image(image_array, i ,j)\n",
        "plt.imshow(convoluted_array)\n",
        "plt.show()\n",
        "\n",
        "#edge detection\n",
        "\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/dog.jpg') \n",
        "cv2_imshow(img)\n",
        "cv2.waitKey(0)\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "img_blur = cv2.GaussianBlur(img_gray, (3,3), 0) \n",
        "sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) \n",
        "sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5)\n",
        "sobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) \n",
        "\n",
        "cv2_imshow(sobelx)\n",
        "cv2.waitKey(0)\n",
        "cv2_imshow(sobely)\n",
        "cv2.waitKey(0)\n",
        "cv2_imshow(sobelxy)\n",
        "cv2.waitKey(0)\n",
        "edges = cv2.Canny(image=img_blur, threshold1=100, threshold2=200) \n",
        "\n",
        "cv2_imshow(edges)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "XQ91in07ybul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Canny edge detection\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image = cv2.imread(\"/content/drive/MyDrive/data/dog.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\"\"\"# Gaussian Blurring\"\"\"\n",
        "\n",
        "def gaussian(x, y, sigma):\n",
        "  return (1 / (2 * np.pi * sigma ** 2)) * np.exp(-((x**2 + y**2) / (2 * sigma ** 2)))\n",
        "\n",
        "def gaussian_kernel(size, sigma):\n",
        "  k = size // 2\n",
        "  kernel = np.zeros((size, size))\n",
        "  for i in range(2 * k + 1):\n",
        "    for j in range(2 * k + 1):\n",
        "      kernel[i][j] = gaussian(i - k, j - k, sigma)\n",
        "  \n",
        "  return kernel\n",
        "\n",
        "kernel = gaussian_kernel(5, 1)\n",
        "image_gaussian = cv2.filter2D(src=image, ddepth=-1, kernel=kernel)\n",
        "\n",
        "\"\"\"# Applying filter\"\"\"\n",
        "\n",
        "image_sobel_x = cv2.filter2D(image_gaussian, ddepth=-1, kernel=np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]))\n",
        "image_sobel_y = cv2.filter2D(image_gaussian, ddepth=-1, kernel=np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]))\n",
        "\n",
        "\"\"\"# Non max suppression\"\"\"\n",
        "\n",
        "magnitude = np.hypot(image_sobel_x, image_sobel_y)\n",
        "magnitude = (magnitude / magnitude.max()) * 255\n",
        "direction = np.arctan2(image_sobel_y, image_sobel_x)\n",
        "direction = direction * 180 / np.pi\n",
        "direction[direction < 0] += 180\n",
        "\n",
        "cv2_imshow(magnitude)\n",
        "\n",
        "image_suppressed = np.zeros((image.shape[0], image.shape[1]))\n",
        "angle_direction_mapping = {\n",
        "    (0, 22.5): (0, 1),\n",
        "    (22.5, 67.5): (-1, -1),\n",
        "    (67.5, 112.5): (1, 0),\n",
        "    (112.5, 157.5): (1, -1),\n",
        "    (157.5, 180): (0, 1)\n",
        "}\n",
        "\n",
        "for i in range(1, image.shape[0] - 1):\n",
        "  for j in range(1, image.shape[1] - 1):\n",
        "    current_pixel_value = magnitude[i][j]\n",
        "    for angle, neighbour_direction in angle_direction_mapping.items():\n",
        "      if angle[0] <= direction[i][j] < angle[1]:\n",
        "        break\n",
        "    neighbour1 = magnitude[i + neighbour_direction[0]][j + neighbour_direction[1]]\n",
        "    neighbour2 = magnitude[i - neighbour_direction[0]][j - neighbour_direction[1]]\n",
        "    if current_pixel_value >= neighbour1 and current_pixel_value >= neighbour2:\n",
        "      image_suppressed[i][j] = current_pixel_value\n",
        "    else:\n",
        "      image_suppressed[i][j] = 0\n",
        "\n",
        "# cv2_imshow((image_suppressed / image_suppressed.max()) * 255)\n",
        "cv2_imshow(image_suppressed)\n",
        "\n",
        "\"\"\"# Double Thresolding\"\"\"\n",
        "\n",
        "low_thresh_ratio = 0.05\n",
        "high_thresh_ratio = 0.09\n",
        "\n",
        "STRONG = 255\n",
        "WEAK = 25\n",
        "\n",
        "high_thresh = image_suppressed.max() * high_thresh_ratio\n",
        "low_thresh = high_thresh * low_thresh_ratio\n",
        "\n",
        "thresholded_result = np.zeros(image.shape)\n",
        "thresholded_result[image_suppressed > high_thresh] = STRONG\n",
        "thresholded_result[(image_suppressed <= high_thresh) & (image_suppressed >= low_thresh)] = WEAK\n",
        "\n",
        "cv2_imshow(thresholded_result)\n",
        "\n",
        "\"\"\"# Edge tracking by Hysterisis\"\"\"\n",
        "\n",
        "for i in range(1, image.shape[0]):\n",
        "  for j in range(1, image.shape[1]):\n",
        "    if thresholded_result[i][j] == WEAK:\n",
        "      if (thresholded_result[i - 1:i + 2, j - 1 : j + 2] == STRONG).any():\n",
        "        thresholded_result[i][j] = STRONG\n",
        "\n",
        "cv2_imshow(thresholded_result)\n"
      ],
      "metadata": {
        "id": "iAsKBUJK0zUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PCA\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import cv2\n",
        "from scipy.stats import stats\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "img = cv2.cvtColor(cv2.imread('rose.jpg'), cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "#Splitting into channels\n",
        "blue,green,red = cv2.split(img)\n",
        "# Plotting the images\n",
        "fig = plt.figure(figsize = (15, 7.2)) \n",
        "fig.add_subplot(131)\n",
        "plt.title(\"Blue Channel\")\n",
        "plt.imshow(blue)\n",
        "fig.add_subplot(132)\n",
        "plt.title(\"Green Channel\")\n",
        "plt.imshow(green)\n",
        "fig.add_subplot(133)\n",
        "plt.title(\"Red Channel\")\n",
        "plt.imshow(red)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "blue_temp_df = pd.DataFrame(data = blue)\n",
        "blue_temp_df\n",
        "\n",
        "df_blue = blue/255\n",
        "df_green = green/255\n",
        "df_red = red/255\n",
        "\n",
        "\n",
        "pca_b = PCA(n_components=50)\n",
        "pca_b.fit(df_blue)\n",
        "trans_pca_b = pca_b.transform(df_blue)\n",
        "pca_g = PCA(n_components=50)\n",
        "pca_g.fit(df_green)\n",
        "trans_pca_g = pca_g.transform(df_green)\n",
        "pca_r = PCA(n_components=50)\n",
        "pca_r.fit(df_red)\n",
        "trans_pca_r = pca_r.transform(df_red)\n",
        "\n",
        "\n",
        "print(trans_pca_b.shape)\n",
        "print(trans_pca_r.shape)\n",
        "print(trans_pca_g.shape)\n",
        "\n",
        "\n",
        "print(f\"Blue Channel : {sum(pca_b.explained_variance_ratio_)}\")\n",
        "print(f\"Green Channel: {sum(pca_g.explained_variance_ratio_)}\")\n",
        "print(f\"Red Channel  : {sum(pca_r.explained_variance_ratio_)}\")\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (15, 7.2)) \n",
        "fig.add_subplot(131)\n",
        "plt.title(\"Blue Channel\")\n",
        "plt.ylabel('Variation explained')\n",
        "plt.xlabel('Eigen Value')\n",
        "plt.bar(list(range(1,51)),pca_b.explained_variance_ratio_)\n",
        "fig.add_subplot(132)\n",
        "plt.title(\"Green Channel\")\n",
        "plt.ylabel('Variation explained')\n",
        "plt.xlabel('Eigen Value')\n",
        "plt.bar(list(range(1,51)),pca_g.explained_variance_ratio_)\n",
        "fig.add_subplot(133)\n",
        "plt.title(\"Red Channel\")\n",
        "plt.ylabel('Variation explained')\n",
        "plt.xlabel('Eigen Value')\n",
        "plt.bar(list(range(1,51)),pca_r.explained_variance_ratio_)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#reconstruct\n",
        "b_arr = pca_b.inverse_transform(trans_pca_b)\n",
        "g_arr = pca_g.inverse_transform(trans_pca_g)\n",
        "r_arr = pca_r.inverse_transform(trans_pca_r)\n",
        "print(b_arr.shape, g_arr.shape, r_arr.shape)\n",
        "\n",
        "\n",
        "img_reduced= (cv2.merge((b_arr, g_arr, r_arr)))\n",
        "print(img_reduced.shape)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (10, 7.2)) \n",
        "fig.add_subplot(121)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(img)\n",
        "fig.add_subplot(122)\n",
        "plt.title(\"Reduced Image\")\n",
        "plt.imshow(img_reduced)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "10uDDr5y1BvK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}